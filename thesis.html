<!DOCTYPE HTML>
<!--
	Phantom by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Code Generation</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">
		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<div class="inner">
							<!-- Nav -->
								<nav>
									<ul>
										<li><a href="#menu">Menu</a></li>
									</ul>
								</nav>

						</div>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<h2>Menu</h2>
						<ul>
							<li><a href="index.html">Home</a></li>
							<li><a href="generic.html">Ipsum veroeros</a></li>
							<li><a href="generic.html">Tempus etiam</a></li>
							<li><a href="generic.html">Consequat dolor</a></li>
							<li><a href="elements.html">Elements</a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">
						<div class="inner">
							<h1>Thesis</h1>
							<div class="box alt">
								<div class="row gtr-uniform">
									<!-- TODO: get image with lanes segmented -->
									<div class="col-12"><span class="image fit"><img src="images/segmentation.png" alt="" /></span></div>

								</div>
							</div>
							<!-- Text -->
								<section>
									<p>Josh worked on a code generation and computer vision project as part of his M.S.
									Thesis at the University of Illinois Urbana-Champaign as well as a subsequent paper.</p>
									<h2>Abstract</h2>
									<p>End-to-end vision-language models often fail to handle compositional tasks,
										necessitating alternative approaches for more complex problem-solving.
										Leveraging the visual programming paradigm, we propose a novel method for
										composing foundational vision models through program generation to tackle
										compositional tasks effectively. We investigate prompting and execution
										strategies that enable the synthesis of fine-tunable code by trainable large
										language models aimed at improving the effectiveness of the programs in solving
										vision-language tasks.</p>

										<p>Capitalizing on the robust compositional reasoning capabilities of large
											language models (LLMs), we employ pre-trained LLMs to architect programs
											constructed using a catalog of pre-defined atomic functions. These atomic
											functions, implemented with pre-trained vision models, serve as the building
											blocks for the visual programs generated by our system. Our methodology
											supports programs in various formats, always offering the flexibility to
											fine-tune the constituent vision models and the LLM code generator.</p>

									<p>This study concentrates on image-based question-answering. This focus
									underscores the critical need for advanced compositional reasoning in interpreting
									and responding to complex visual queries. Our evaluation encompasses the executability
									and correctness of the produced programs, providing a comprehensive assessment of
									our approach's effectiveness.</p>

									<p>This paper lays the groundwork for a subsequent investigation into the joint
										training of the LLMs and atomic functions, setting the stage for significant
										advancements in program generation and compositional reasoning in computer vision.</p>

								</section>
						</div>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>